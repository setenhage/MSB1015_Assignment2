---
title: "MSB1015_Assignment 2"
author: "Suzanne ten Hage"
date: "12 october 2019"
output: html_notebook
---

**Project Description**
Chemical properties, such as the boiling point, can be derived from the structure of a chemical compound. In 1947, Harry Wiener already made a correlation model to link structural features to boiling points (ref1). The idea to use mathematical models to predict chemical properties from compound structures has been expaned since then. 

In this project I use a SPARQL query to obtain the smiles and boiling points of simple alkanes from WikiData. I use the smiles to get descriptors from the CDK database. These descriptors contain information on the structural properties of the alkanes (see section 2 for more details). Finally, I train a Partial Least Squares (PLS) model to predict these properties from the chemical properties of the compounds and plot the results. 

**0. Installation**
The project requires several packages. The piece of code in this section checks automatically for missing packages and installs them. 

The rJava package requires Java to be installed. The code has been developed using Java version 1.8.0_191. A tutorial on how to install this Java Version can be found here: https://downlinko.com/download-install-jdk-8-windows.html 

```{r}
#Required packages for this code. 
packages <- c("WikidataQueryServiceR", 
              "rJava", 
              "rcdk", 
              "caTools",
              "pls", 
              "Metrics"
              )

#Installation of missing packages 
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
    install.packages(setdiff(packages, rownames(installed.packages()))) 
    }

#Load packages
library("WikidataQueryServiceR")
library('rJava')
library('rcdk')
library('caTools')
library('pls')
library('Metrics')

```

**1. Get the data from WikiData.** 
In this section I use the WikidataQueryServiceR package to obtain all simple alkines with known boiling points from WikiData. I get their name, boiling point, boiling point unit and smiles. 

```{r}

data_wikidata = query_wikidata('SELECT DISTINCT ?comp ?compLabel ?bp ?bpUnit ?bpUnitLabel ?smiles WHERE {   
    ?comp wdt:P31/wdt:P279* wd:Q41581 ;
    p:P2102 [ps:P2102 ?bp ;           
             psv:P2102/wikibase:quantityUnit  
             ?bpUnit         
            ] ;
    wdt:P233 ?smiles.
    SERVICE wikibase:label { bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en". } 
    } '
)


```

**2. Get the descriptors of the alkane structures**
In this section, I get descriptors for all alkanes from CDK based on their smiles. These descriptors will be used later as predictors in the PLS model. 

```{r}

#Reformatting of smiles into correct format for CDK. Kekulise checks for electrons, and prevents parsing of incorrect smiles. 
parsed_smiles <- parse.smiles(data_wikidata$smiles, kekulise=TRUE)

#Determine which descriptors to get. 
descriptor_names <- c(
'org.openscience.cdk.qsar.descriptors.molecular.APolDescriptor',
'org.openscience.cdk.qsar.descriptors.molecular.WienerNumbersDescriptor',
'org.openscience.cdk.qsar.descriptors.molecular.MDEDescriptor',
'org.openscience.cdk.qsar.descriptors.molecular.FragmentComplexityDescriptor'
)

#Get descriptors
data_descriptors <- eval.desc(parsed_smiles, descriptor_names)

```

**3. Data pre-processing**
3a) Not all boiling points in the database are in kelvin, which is the SI unit for temperature. Before I continue, I make sure all temperatures are in kelvin. 

```{r}

##CELCIUS -> KELVIN
#Find all rownumbers of the values in Celcius. 
celcius <-  which(grepl('degree Celsius', data_wikidata$bpUnitLabel))

for (i in 1:length(celcius)) {
  #Convert the value to kelvin
  data_wikidata$bp[celcius[i]] <- data_wikidata$bp[celcius[i]] + 273.15
  #Convert the label to kelvin. 
  data_wikidata$bpUnitLabel[celcius[i]] <- 'kelvin'
}

##FAHRENHEIT -> KELVIN
#Find all rownumbers of the values in Fahrenheit. 
fahrenheit <- which(grepl('degree Fahrenheit',data_wikidata$bpUnitLabel))

for (i in 1:length(fahrenheit)) {
  #Convert the value to kelvin
  data_wikidata$bp[fahrenheit[i]] <- (data_wikidata$bp[fahrenheit[i]] + 459.67) * (5/9)
  #Convert the label to kelvin. 
  data_wikidata$bpUnitLabel[fahrenheit[i]] <- 'kelvin'
}

```

3b) Combine the descriptors and boiling points in one dataset, so we can use this dataset for the PLS. I remove the columns with (almost) all zeros, because 
```{r}

#Fuse the boiling points from data.raw and descriptors into one dataset. 
data_combined <- data.frame(data_descriptors, data_wikidata$bp)

#Define which columns to remove. 
remove_columns <- c("MDEC.13", "MDEC.14", "MDEC.22", "MDEC.23", "MDEC.24", "MDEC.33", "MDEC.34", "MDEC.44", "MDEO.11", "MDEO.12", "MDEO.22", "MDEN.11", "MDEN.12", "MDEN.13", "MDEN.22", "MDEN.23", "MDEN.33")

#Remove all empty columns from the dataset.
data_combined <- data_combined[ , -which(names(data_combined) %in% remove_columns)]

```

3c) To be able to test how well the model I train performs, it is necessary to keep a part of our data aside as testing data. In the following code you can easily change the size of the test data by adjusting percentage_test. 
 
```{r}

#Percentage of data to go into the test-set. 
percentage_test <- 0.25

#Splitting data into a training and test set. 
set.seed(101) 
sample = sample.split(data, SplitRatio = percentage_test)
train = subset(data, sample == FALSE)
test  = subset(data, sample == TRUE)

```

**4. Null model**
The null model is the most simple model possible: the mean of the data. This model can be used as a reference to see whether the PLS model performs better. 

```{r}

#Create null_model
null_model <- mean(train$data_raw.bp)

#Get error of null model
error_null_model <- rmse(test$data_raw.bp, null_model)

```

**5. Partial Least Squares**
Here, I train the PLS model with the training data, and use the model to predict the boiling points of the test data. 

```{r}

#Training of the PLS model. 
PLS_model <- plsr(data_raw.bp ~ ., 
                  data = train, 
                  validation = "CV"
                  )

#test.try <- test[,c(1:34)];
#Predict the boiling points of the test set. 
predicted.bp <- predict(PLS_model, test)

#Calculate the error. 
error <- RMSEP(PLS_model, newdata = test)

```

**6. Visualization**

```{r} 

#Plot the error vs. the number of components
plot(error)

#Plot the predicted data vs. the original data. 
plot(test$data_raw.bp, predicted.bp[,,3], xlim=c(300,1000), ylim=c(300,1000))

plot(test$data_raw.bp, rep(null_model, length(test$data_raw.bp)))

#Correlation between predicted and original test data. 
corcoef <- cor(predicted.bp[,,3], test$data_raw.bp) 

```

**7. References**
ref1: Wiener H. Structural Determination of Paraffin Boiling Points. Journal of the American Chemical Society. 1947 Jan;69(1):17â€“20.
